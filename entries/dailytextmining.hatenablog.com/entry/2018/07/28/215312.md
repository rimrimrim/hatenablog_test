---
Title: 2018/7/27【34日目】「教えて!goo」のオシエルの中身を聞いてきた
Category:
- 180日間テキストマイニング
Date: 2018-07-28T21:53:12+09:00
URL: https://dailytextmining.hatenablog.com/entry/2018/07/28/215312
EditURL: https://blog.hatena.ne.jp/rimt/dailytextmining.hatenablog.com/atom/entry/10257846132605450382
---

金曜日にデベロッパーサミット（通称、デブサミ）が行われていましたので行ってきました。


[https://event.shoeisha.jp/devsumi/20180727:embed:cite]


全体的に機械学習の話が多かったのですが、『「教えて!goo」3000万件のQAデータから、世界初の長文生成AIが生まれるまで～AIによる恋愛相談の裏側～ 中辻 真 [NTTレゾナント]』という講演が自然言語処理に関するもので面白かったのでブログに書いておきます。

## 世界初の長文生成AIとは
教えて！gooというYhoo 知恵袋のようなサービスがあります。
そこで質問に対して機械的にテキスト生成を行い、Aiにより自動回答を行うのが世界初の長文生成AIである「オシエル」です。

もともとこういったQ&Aサイトにおける
- 質問に対する回答が遅い
- 質問に対する回答がない
- 質問に対する最適な回答がない
といった問題点を解決するために開発されたそうです。

ちなみに、gooが考えているAI活用の4ステップのうちの最初のステップのようです。詳しくはこちらのPDFにかいてあります。

[https://www.ntt.com/content/dam/nttcom/hq/jp/business/go-event/pdf/seminar/4-7.pdf]



## オシエルの内部
「教えて!goo」のようなQ&Aサイトの質問には2種類の質問があるそうです。

- Factoid：答えがある（富士山の高さは？とか）
- Non-Factoid：明確な答えがない

それで、Non-Factoidの質問に答える方法ですが、既存の方法では以下の手順が

- Word2bectで単語ベクトル生成
- 時系列DL文書ベクトルを生成
- 質問と答えのベクトルを類似度計算によりマッチングを最適化

というプロセスを踏んでるそうです。
このプロセスを踏んだQA-LSTMというアルゴリズムの研究論文はこちらだそうです。

- Improved Representation Learning for Question Answer Matching

[http://www.aclweb.org/anthology/P16-1044]



オシエルの場合はこれとは違い、次のようなプロセスを踏んでいるそうです。

- 複雑かつ長文の回答生成実現のため、回答の抽象的なシナリオを定義
- 質文と回答文のマッチングと、回答文間の組み合わせを同時に最適化
- 結論と履修の流れを自然にするため、アテンションメカニズムを導入

このあたりのことはこちらの論文に書いてありそうです。

- CAN AI GENERATE LOVE ADVICE?: TOWARD NEURAL ANSWER GENERATION FOR NON-FACTOID QUESTIONS

[https://openreview.net/pdf?id=ryQbbFile]


他に講演中に紹介されていた論文。

- LSTMを用いたパーソナル対話技術

[https://confit.atlas.jp/guide/event-img/jsai2018/4G2-02/public/pdf?type=in]


- A Neural Conversational Model

[https://arxiv.org/pdf/1506.05869.pdf]


170日目くらいになったらこれらに目を通してみたいですね。
