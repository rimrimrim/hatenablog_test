---
Title: 2018/7/18【26日目】n-gramの使い道を調べてみた
Date: 2018-07-19T21:56:09+09:00
URL: https://dailytextmining.hatenablog.com/entry/2018/07/19/215609
EditURL: https://blog.hatena.ne.jp/rimt/dailytextmining.hatenablog.com/atom/entry/10257846132602700297
---

昨日の段階では、n-gramを使って何かしらの分析をしようと思いましたが、そもそもn-gramが何の役に立つのかわからないので、いくつか論文を当たりたいと思います。

Google Scholarで検索してみましたら、いくつか出てきましたので、下記の論文を読んでみました。

- n-gram 分布を用いた近代日本語小説文の著者推定
- 近代日本小説家 8 人による文章の n-gram 分布を用いた著者判別
- 平仮名 N-gram による平仮名列の誤り検出とその修正

それではn-gramの使い道について書いていきます。

##著者推定
n-gramを使うと、その文書を書いた人を推定できるそうです。論文によると芥川龍之介の特長をn-gramで表すと「えない」、「の代り」、「をしな」の3つだそうです。この3つが出現すると芥川龍之介の可能性が高いそうです。

昨日、ライブラリを使用したn-gramとfor文で作成したn-gramがありましたが、この2つはちゃんと区別があるそうです。ライブラリで作成したのが<b>文字n-gram</b>、for文で作成したのが<b>単語n-gram</b>というそうです。そのままですね。

それで、著者推定を行うには一文あたりの平均文字数、一語あたりに含まれる文字数、単語の使用頻度があるそうですが、日本語を扱う場合は、文字n-gramが良いそうです。その場合は3-gramが精度がいいそうです。

##文章の誤りの検出
n-gramを使うと文章の校正ができるそうです。論文（1990年）によると単語n-gramの利用は検索コストが高くまだ評価はされていないそうです。今なら手軽にできそうですね。

論文では、検索コストを下げるために、平仮名だけで行なっていますが、この場合は4gramが優秀だったそうです（コーパスとして新聞5年分。もっとコーパスを巨大にすれば5gramがいいそうです）。

##著者の特徴を見つける
と言うわけで、文章の誤りを検出するのはハードルが高そうなので、著者推定を行いたいと思います。

1ヶ月で一番呟いた回数が多い（なんと73回。すごいですね。）31位の福岡聖菜 @seina_fuku48の特徴をみてみます。

```
import MeCab
import ngram

text = open('fukuoka_seina.csv', 'r')

seina = text.read()
lists = []
index = ngram.NGram(N=3)
for two_gram in index.ngrams(index.pad(seina)):
    lists.append(two_gram)
len(lists)
```
実行結果
```
7231
```
とりあえず、7231個の要素を持った配列ができました。
配列の中を数えるのは<b>2018/6/28【6日目】頻出単語の数を調べる</b>で勉強したCounter関数が使えそうです。

```
from collections import Counter
count = Counter(list)
print(count)
```
実行結果。
```
Counter({'htt': 152, 'ttp': 152, 'tps': 152, 'ps:': 152, 's:/': 152, '://': 152, '//t': 152, '/t.': 152, 't.c': 152, '.co': 152, 'co/': 152, ' ht': 144, '"\n"': 144, 'ちゃん': 68, '！！\n': 44, 'せいち': 42, 'いちゃ': 42, 'ました': 40, 'うござ': 38, 'ござい': 38, 'ざいま': 38, '… h': 34, 'チョコ': 30, 'ョコミ': 30, 'コミン': 30, '\n"#': 28, '＼(^': 28, '(^o': 28, '^o^': 28, 'o^)': 28, '^)／': 28, 'います': 28, 'ミント': 26, '、、\n': 24, '? h': 24, 'かった': 24, 'ありが': 24, 'りがと': 24, 'がとう': 24, '#せい': 24, ')／\n': 22, '\n#き': 22, '#きょ': 22, 'きょう': 22, 'ょうの': 22, 'うのせ': 22, 'のせい': 22, '\n"お': 22, 'ゃん\n': 20, 'ようご': 20, '\n今日': 20, 'した✨': 18, '、、、': 18, 'とうご': 18, 'ROO': 18, 'OOM': 18, '"おは': 18, 'おはよ': 18
（以下、省略）
```
思ったよりもきれいに拾えました。

- 'せいち': 42,
- 'いちゃ': 42,
- 'コミン': 30,
- '＼(^': 28,
- ょうの': 22,
- 'ようご': 20,

らへんが福岡聖菜の特徴ぽいですね。
明日はこれらを使って著者推定を行なっていきたいと思います。

##今日の結果
今日のAKBの呟き件数は49件でした。
[f:id:rimt:20180719215523p:plain]

まし、がここまで大きいのもあまりみないですね。

```
{'楽しい': 7, '嬉しい': 6, '暑い': 6, 'よい': 3, 'すごい': 3, 'ない': 2, 'あおい': 2, 'やすい': 2, '凄い': 2, 'いい': 2, '面白い': 2, '短い': 1, '難しい': 1, '悪い': 1, '弱い': 1, 'すっごい': 1, 'がたい': 1, '珍しい': 1, '恥ずかしい': 1, 'っぽい': 1, '優しい': 1, '多い': 1, '濃い': 1, 'かっこよい': 1})
'さん': 17, 'ちゃん': 14, '笑': 12, '公演': 10, '人': 10, '日': 9, '楽しい': 7, '嬉しい': 6, '暑い': 6, '私': 6, 'みなさん': 6, '今日': 6, '時間': 5, 'ん': 5, 'こと': 5, '大会': 5, '写真': 5,
'する': 31, 'さん': 17, 'ちゃん': 14, 'くださる': 13, '笑': 12, '公演': 10, '人': 10, 'ある': 10, '日': 9, '見る': 9, '言う': 8, '楽しい': 7, 'くる': 7, 'なる': 7, 'いる': 7, '嬉しい': 6, '暑い': 6, '私': 6, 'みなさん': 6, '今日': 6, '行く': 6, '時間': 5, 'ん': 5, 'こと': 5, '大会': 5, '写真': 5, 'せる': 5, 'いただく'
```

##今日勉強したこと
- n-gramの使い道
- 特徴量の検出

##参考文献

- 松浦司, 金田康正(1999)「n‐gram分布を用いた近代日本語小説文の著者推定」, 情報処理学会研究報告 巻：99 号：95(NL-134) ページ：31-38
- 松浦司, 金田康正(2000)「近代日本小説家8人による文章のn‐gram分布を用いた著者判別」, 情報処理学会研究報告 巻：2000 号：53(NL-137) ページ：1-8
- 新納浩幸, 「平仮名N‐gramによる平仮名列の誤り検出とその修正」, 情報処理学会論文誌 巻：40 号：6 ページ：2690-2698
