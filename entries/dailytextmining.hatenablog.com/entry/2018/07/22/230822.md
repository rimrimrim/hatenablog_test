---
Title: 2018/7/21【29日目】ランダムフォレストよりベイズの方がよさそうだった
Category:
- 180日間テキストマイニング
Date: 2018-07-22T23:08:22+09:00
URL: https://dailytextmining.hatenablog.com/entry/2018/07/22/230822
EditURL: https://blog.hatena.ne.jp/rimt/dailytextmining.hatenablog.com/atom/entry/10257846132603624213
---

昨日のtweetの長さで学習データと正解データは手元にできたので、一応これだけでも動きます。

```python
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

names = pd.read_csv('name_20180721.csv',
                   sep="\n", 
                   encoding='utf-8')

tweets = pd.read_csv('tweet_20180721.csv',
                    sep=r"\s+",
                    encoding='utf-8',
                    dtype = None, 
                    error_bad_lines=False)

names.loc[names['name'] != "seina_fuku48"] = 0
names.loc[names['name'] == "seina_fuku48"] = 1

nagasa_atai = []
for content in tweet["tweet"]:
    lenght = len(content)
    nagasa_atai.append(lenght)
    
tweets['nagasa'] = np.array(nagasa_atai)

X_train = tweets.drop('tweet', axis = 1)
Y_train = np.asarray(names["name"], dtype="|S6")

clf = RandomForestClassifier(max_depth=2, random_state=0)
clf.fit(X_train, Y_train)

print(clf.predict([["130"]]))
```
```
[b'0']
```
ただ、tweetの長さごときでは、当然のごとく著者推定は当たりませんね。もう少し学習させるためのデータが増やす必要があります。

今までやったTfidfとかngramを実装していこうと思ったのですが、どうもデータが大きすぎるのかfor文を実行すると落ちますね。データを今日の分にだけにして、取りあえず実装していきたいと思います。

shapeするとこんな感じです。

```python
print(names.shape)
print(tweets.shape)
```
```
(96, 1)
(96, 1)
```
ちょうど握手会があったらしくて、96件も投稿されてますね。。。多い。

##教科書通りに実装してみる
1日かけていろいろやってみたのですが、やっぱり自然言語を学習させるのは難しいですね笑。

二進も三進もいかないので、『Machine Learning実践の極意 機械学習システム構築の勘所をつかむ! 
』という本の通りに実装してみます。

- 1 学習データとテストデータにわける

```python
name_tweet = pd.read_csv('name_tweet_20180722.csv',
                   sep=",", 
                   encoding='utf-8')

name_tweet['name'].loc[name_tweet['name'] != "seina_fuku48"] = int(0)
name_tweet['name'].loc[name_tweet['name'] == "seina_fuku48"] = int(1)

split = 0.7
name_tweet_train = name_tweet[:int(split*len(name_tweet))]
name_tweet_test = name_tweet[int(split*len(name_tweet) +1):]
```
なるほど、まずはテスト用に分けないといけないんですね。
ここでのname_tweetの数は96なので、0.7をかけた67までスライドをしてname_tweet_trainに代入、テスト用には１をプラスした68以降をスライドしてname_tweet_testに代入しているようです。

- 2 文字を数値化
```python
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
features = vectorizer.fit_transform(name_tweet_train.tweet)
print(features)
```
13日目で出てきたCountVectorizerを使ってテキストを数値化しているようです。プリントするとこんな感じです。

```
  (0, 25)	1
  (0, 61)	1
  (0, 77)	1
  (0, 3)	1
  (0, 302)	1
  (0, 57)	1
  (0, 33)	1
  (0, 42)	1
  (0, 36)	1
  (0, 29)	1
  (0, 233)	1
（中略）
```

- 3 テストデータの方も特徴量を追加する
```python
test_features = vectorizer.transform(tweet_test.tweet)
i = 68
j = 10
words = vectorizer.get_feature_names()[i:i+10]
pd.DataFrame(features[j:j+7,i:i+10].todense(), columns=words)
```
テストデータなので、おそらく68番目以降を入れて行きます。その他の数値は不明です。

- 4 学習させる
```python
y_train = name_tweet_train.name.astype('int')
clf1 = RandomForestClassifier(max_depth=2, random_state=0)
clf1.fit(features, y_train)
```
正解データは、ちゃんと型を指定しないとエラーを起こしますので、.astype('int’)でちゃんとintにします。

実行結果。
```
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=2, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=0, verbose=0, warm_start=False)
```
ちゃんと学習できたようです。
学習したモデルをテストデータに当てはめてみます。
```python
pred1 = clf1.predict_proba(test_features)
```
これを可視化します。
```python
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
%matplotlib inline
from matplotlib import pyplot

y_test = name_tweet_test.name.astype('int')

def perfomance(y_true, pred, color="g", ann=True):
              acc = accuracy_score(y_true, pred[:,1] > 0.5)
              auc = roc_auc_score(y_true, pred[:,1])
              fpr, tpr, thr = roc_curve(y_true, pred[:,1])
              pyplot.plot(fpr, tpr, color, linewidth="3")
              pyplot.annotate("AUC: %0.2F" % auc, (0.1,0.8), SIZE =14)
perfomance(y_test, pred1)
```
[f:id:rimt:20180722230218p:plain]


直線の図ができました。こういった図をRoc曲線というらしいです。

Roc曲線（ロック曲線と読むらしい）は、与えられた値からTrueかFalseを判断する際に使用するそうです。Trueの時に上に進んで、Falseの時に右にいくみたいです（そんな単純でもないと思いますが）。それで左上にシフトしていくほど、いいモデルだそうです。

今回の場合、ほぼ直線ですが、Roc曲線というくらいですので、直線の場合は全く有効ではないとのことでした笑。

取りあえず、実行はできるようなので、1ヵ月分のデータを追加してみます。

##一ヶ月分のデータを入れてみる

流石に1かヶ月分ですと、nanが出てきて一度では読みこないですね。
```
ValueError: np.nan is an invalid document, expected byte or unicode string.

```

次のコマンドでNaNの場所を探せるらしいです。
```python
name_tweet[name_tweet.isnull().any(1)]
```
実行結果はこんな感じです。
```
	name	tweet
148	0	NaN
149	0	NaN
158	0	NaN
159	0	NaN
160	0	NaN
163	0	NaN
```

NaNの場所がわかったので、NaNの周辺をprintしてどのようになっているのか見て修正していきます。

```python
print(name_tweet[1625:1619])
```
```
     name                                              tweet
1615    0                                SHOWROOMします！みにきてね❤︎
1616    0  握手会ありがとうございました〜！?今日も楽しかったです?\n明日はもっともーっときてくれると...
1617    0                                _\n友達居ない風"の写真も撮れたよ?
1618    0                                                NaN
1619    0                                                NaN
```
ほとんどの場合、コンマがあったり、ダブルクオテーションがあったりするだけでした。これらを修正して、学習。もう一度、Roc曲線を出してみます。
[f:id:rimt:20180722230143p:plain]


まさかのマイナス。

#＃学習モデルをベイズにしてみる
ランダムフォレストが残念な結果になってしまいましたので、教科書通りベイズの方にしてみましょう。
```python
from sklearn.naive_bayes import MultinomialNB
model= MultinomialNB()
model.fit(features, name_tweet_train.name.astype('int'))
pred2 = model.predict_proba(test_features)

%matplotlib inline
from matplotlib import pyplot

y_test = name_tweet_test.name.astype('int')

def perfomance(y_true, pred, color="g", ann=True):
              acc = accuracy_score(y_true, pred[:,1] > 0.5)
              auc = roc_auc_score(y_true, pred[:,1])
              fpr, tpr, thr = roc_curve(y_true, pred[:,1])
              pyplot.plot(fpr, tpr, color, linewidth="3")
              pyplot.annotate("AUC: %0.2F" % auc, (0.1,0.8), SIZE =14)
perfomance(y_test, pred2)
```
[f:id:rimt:20180722230159p:plain]


こちらはそこそこ曲線に近くなりました。
まだまだ勉強が足りないので、ベイズを学習して、そのうちその3に進みます。


##今日の結果
上でも書きましたが、今日は握手会があったこともあり、96件も投稿されていました。

[f:id:rimt:20180722225511p:plain]

```
'嬉しい': 16, '楽しい': 9, '早い': 7, 'すごい': 4, '可愛い': 3, '良い': 3, 'よろしい': 3, '暑い': 3, '多い': 3, 'っぽい': 2, 'いい': 2, '新しい': 1, '悪い': 1, '甘い': 1, 'よい': 1, '美味しい': 1, '珍しい': 1, '宜しい': 1, 'かわいい': 1, 'ない': 1, '凄い': 1, '懐かしい': 1, '遅い': 1, '面白い': 1})

'アクシュカイ': 57, '部': 53, '今日': 34, '明日': 24, 'レーン': 22, '方': 18, '嬉しい': 16, '券': 16, 'お願い': 16, 'ちゃん': 16, '幕張メッセ': 14, 'ん': 13, '当日': 12, 'たくさん': 11, '大会': 10, '握手': 10, '夏': 10, '楽しい': 9, '時': 9, 'の': 8, '写真': 8, '気': 8, '早い': 7, 'よう': 7, 'ユニット': 7, '笑': 7, '皆さん': 7, '増し': 6, '応援': 6, '私': 6, 'エーケービーフォーティーエイト': 6, 'パレード': 6, '人': 6, '日': 6,
'する': 58, 'アクシュカイ': 57, '部': 53, '今日': 34, 'くださる': 28, '明日': 24, '来る': 24, 'レーン': 22, 'なる': 19, '方': 18, '嬉しい': 16, '券': 16, 'お願い': 16, 'ちゃん': 16, '幕張メッセ': 14, 'ん': 13, 'ける': 13, '当日': 12, 'いる': 12, 'たくさん': 11, '大会': 10, '握手': 10, '夏': 10, '楽しい': 9, '時': 9, 'くれる': 9, '会う': 9, 'ある': 9, 'てる': 9, 'くる': 9, 'の': 8, '写真': 8, '気': 8, '使える': 8,
```
